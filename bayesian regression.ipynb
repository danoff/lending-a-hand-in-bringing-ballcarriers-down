{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6051d31f-ace1-4257-89e6-a3ffa876e147",
   "metadata": {},
   "source": [
    "Source: https://medium.com/intuition/gentle-introduction-of-bayesian-linear-regression-c83da6b0d1f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b9e0ea-6c99-46f2-8ec1-a6a3e12b12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytensor.tensor as at\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4165d7-6940-4da3-a596-5547ad19544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]\n",
      "scipy: 1.12.0\n",
      "numpy: 1.26.4\n",
      "matplotlib: 3.8.4\n",
      "pandas: 2.2.2\n",
      "sklearn: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the versions of libraries\n",
    "\n",
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Load libraries\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcdbb0d1-57e2-41ea-9501-4c3402c6976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speed_dist_data_20231228.csv', header=0)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35576e88-dbcc-4e9f-ba7e-0434d1a9a811",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/14940743/selecting-excluding-sets-of-columns-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab29640c-085b-4942-a18f-b4ee0a87753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['ballCarrierSpeed','toPlayerDistanceToBallCarrier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54ec408c-fd34-44d5-a449-929e13a1d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ballCarrierSpeed</th>\n",
       "      <th>toPlayerDistanceToBallCarrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.23</td>\n",
       "      <td>11.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.23</td>\n",
       "      <td>12.4279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.23</td>\n",
       "      <td>31.5794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ballCarrierSpeed  toPlayerDistanceToBallCarrier\n",
       "1              6.23                        11.0136\n",
       "2              6.23                        12.4279\n",
       "3              6.23                        31.5794"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2abf3c0-7f3e-4434-9a04-ae254d2a0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.duplicated()]\n",
    "df1 = df1.dropna().astype(float)\n",
    "\n",
    "columns = df1.columns.values[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1f0813a-209a-4224-ae9f-98b4d9f21d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test size\n",
      "(5000932,) (555660,) (5000932,) (555660,)\n"
     ]
    }
   ],
   "source": [
    "X = df1.ballCarrierSpeed.values\n",
    "y = df1.toPlayerDistanceToBallCarrier.values\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "print('train and test size')\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc45843-98d0-41b8-91b2-7136cc4b04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_bayesian = pm.Model(coords={\"predictors\": columns})\n",
    "\n",
    "with test_score_bayesian:\n",
    "    # posterior variance\n",
    "    sigma = pm.HalfNormal(\"sigma\", 25)\n",
    "\n",
    "    # beta\n",
    "    beta = pm.Normal(\"beta\", 0, 10, dims=\"predictors\")\n",
    "    beta0 = pm.Normal(\"beta0\", 0, 10)\n",
    "\n",
    "    mu = beta0 + at.dot(X_train, beta)\n",
    "    \n",
    "    y_hat = pm.Normal(\"y_hat\", mu=mu, sigma=sigma, observed=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "030c25cb-3ce2-4924-96ae-de69285f8784",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "This function requires the python library graphviz, along with binaries. The easiest way to install all of this is by running\n\n\tconda install -c conda-forge python-graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model_graph.py:348\u001b[0m, in \u001b[0;36mModelGraph.make_graph\u001b[0;34m(self, var_names, formatting, save, figsize, dpi, node_formatters)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pm\u001b[38;5;241m.\u001b[39mmodel_to_graphviz(test_score_bayesian)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model_graph.py:642\u001b[0m, in \u001b[0;36mmodel_to_graphviz\u001b[0;34m(model, var_names, formatting, save, figsize, dpi, node_formatters)\u001b[0m\n\u001b[1;32m    636\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormattings other than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are currently not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    639\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    640\u001b[0m     )\n\u001b[1;32m    641\u001b[0m model \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mmodelcontext(model)\n\u001b[0;32m--> 642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelGraph(model)\u001b[38;5;241m.\u001b[39mmake_graph(\n\u001b[1;32m    643\u001b[0m     var_names\u001b[38;5;241m=\u001b[39mvar_names,\n\u001b[1;32m    644\u001b[0m     formatting\u001b[38;5;241m=\u001b[39mformatting,\n\u001b[1;32m    645\u001b[0m     save\u001b[38;5;241m=\u001b[39msave,\n\u001b[1;32m    646\u001b[0m     figsize\u001b[38;5;241m=\u001b[39mfigsize,\n\u001b[1;32m    647\u001b[0m     dpi\u001b[38;5;241m=\u001b[39mdpi,\n\u001b[1;32m    648\u001b[0m     node_formatters\u001b[38;5;241m=\u001b[39mnode_formatters,\n\u001b[1;32m    649\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model_graph.py:350\u001b[0m, in \u001b[0;36mModelGraph.make_graph\u001b[0;34m(self, var_names, formatting, save, figsize, dpi, node_formatters)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function requires the python library graphviz, along with binaries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe easiest way to install all of this is by running\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mconda install -c conda-forge python-graphviz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m node_formatters \u001b[38;5;241m=\u001b[39m node_formatters \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    357\u001b[0m node_formatters \u001b[38;5;241m=\u001b[39m update_node_formatters(node_formatters)\n",
      "\u001b[0;31mImportError\u001b[0m: This function requires the python library graphviz, along with binaries. The easiest way to install all of this is by running\n\n\tconda install -c conda-forge python-graphviz"
     ]
    }
   ],
   "source": [
    "pm.model_to_graphviz(test_score_bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d427b774-54ff-46fb-98cf-39e30685f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for gemv (beta * y + alpha * dot(A, x)). y: (1,), A: (1, 1), x: (5000932,)\nApply node that caused the error: Gemv{inplace}(AllocEmpty{dtype='float64'}.0, 1.0, ExpandDims{axis=0}.0, [4.62 2.23 ... 6.98 6.75], 0.0)\nToposort index: 9\nInputs types: [TensorType(float64, shape=(1,)), TensorType(float64, shape=()), TensorType(float64, shape=(1, None)), TensorType(float64, shape=(5000932,)), TensorType(float64, shape=())]\nInputs shapes: [(1,), (), (1, 1), (5000932,), ()]\nInputs strides: [(8,), (), (8, 8), (8,), ()]\nInputs values: [array([0.]), array(1.), array([[-0.87218071]]), 'not shown', array(0.)]\nOutputs clients: [[Add(ExpandDims{axis=0}.0, Gemv{inplace}.0)]]\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/link/vm.py:407\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thunk, node, old_storage \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthunks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_thunk_clear, fillvalue\u001b[38;5;241m=\u001b[39m()\n\u001b[1;32m    406\u001b[0m ):\n\u001b[0;32m--> 407\u001b[0m     thunk()\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m old_s \u001b[38;5;129;01min\u001b[39;00m old_storage:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/graph/op.py:524\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[0;32m--> 524\u001b[0m     r \u001b[38;5;241m=\u001b[39m p(n, [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m i], o)\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/tensor/blas.py:222\u001b[0m, in \u001b[0;36mGemv.perform\u001b[0;34m(self, node, inputs, out_storage)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for gemv \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(beta * y + alpha * dot(A, x)). y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, A: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m check_init_y():\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for gemv (beta * y + alpha * dot(A, x)). y: (1,), A: (1, 1), x: (5000932,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m test_score_bayesian:\n\u001b[0;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:746\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto-assigning NUTS sampler...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m joined_blas_limiter():\n\u001b[0;32m--> 746\u001b[0m         initial_points, step \u001b[38;5;241m=\u001b[39m init_nuts(\n\u001b[1;32m    747\u001b[0m             init\u001b[38;5;241m=\u001b[39minit,\n\u001b[1;32m    748\u001b[0m             chains\u001b[38;5;241m=\u001b[39mchains,\n\u001b[1;32m    749\u001b[0m             n_init\u001b[38;5;241m=\u001b[39mn_init,\n\u001b[1;32m    750\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    751\u001b[0m             random_seed\u001b[38;5;241m=\u001b[39mrandom_seed_list,\n\u001b[1;32m    752\u001b[0m             progressbar\u001b[38;5;241m=\u001b[39mprogressbar,\n\u001b[1;32m    753\u001b[0m             jitter_max_retries\u001b[38;5;241m=\u001b[39mjitter_max_retries,\n\u001b[1;32m    754\u001b[0m             tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    755\u001b[0m             initvals\u001b[38;5;241m=\u001b[39minitvals,\n\u001b[1;32m    756\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    757\u001b[0m         )\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# Time to draw/evaluate numeric start points for each chain.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     ipfns \u001b[38;5;241m=\u001b[39m make_initial_point_fns_per_chain(\n\u001b[1;32m    762\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    763\u001b[0m         overrides\u001b[38;5;241m=\u001b[39minitvals,\n\u001b[1;32m    764\u001b[0m         jitter_rvs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(),\n\u001b[1;32m    765\u001b[0m         chains\u001b[38;5;241m=\u001b[39mchains,\n\u001b[1;32m    766\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:1427\u001b[0m, in \u001b[0;36minit_nuts\u001b[0;34m(init, chains, n_init, model, random_seed, progressbar, jitter_max_retries, tune, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing NUTS using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1422\u001b[0m cb \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1423\u001b[0m     pm\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mCheckParametersConvergence(tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1424\u001b[0m     pm\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mCheckParametersConvergence(tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1425\u001b[0m ]\n\u001b[0;32m-> 1427\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m _init_jitter(\n\u001b[1;32m   1428\u001b[0m     model,\n\u001b[1;32m   1429\u001b[0m     initvals,\n\u001b[1;32m   1430\u001b[0m     seeds\u001b[38;5;241m=\u001b[39mrandom_seed_list,\n\u001b[1;32m   1431\u001b[0m     jitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjitter\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m init,\n\u001b[1;32m   1432\u001b[0m     jitter_max_retries\u001b[38;5;241m=\u001b[39mjitter_max_retries,\n\u001b[1;32m   1433\u001b[0m )\n\u001b[1;32m   1435\u001b[0m apoints \u001b[38;5;241m=\u001b[39m [DictToArrayBijection\u001b[38;5;241m.\u001b[39mmap(point) \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m initial_points]\n\u001b[1;32m   1436\u001b[0m apoints_data \u001b[38;5;241m=\u001b[39m [apoint\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m apoint \u001b[38;5;129;01min\u001b[39;00m apoints]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:1321\u001b[0m, in \u001b[0;36m_init_jitter\u001b[0;34m(model, initvals, seeds, jitter, jitter_max_retries)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m jitter_max_retries:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1321\u001b[0m         model\u001b[38;5;241m.\u001b[39mcheck_start_vals(point)\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SamplingError:\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# Retry with a new seed\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         seed \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model/core.py:1790\u001b[0m, in \u001b[0;36mModel.check_start_vals\u001b[0;34m(self, start)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     valid_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value_names_set)\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome start parameters do not appear in the model!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1787\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid keys are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1788\u001b[0m     )\n\u001b[0;32m-> 1790\u001b[0m initial_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_logps(point\u001b[38;5;241m=\u001b[39melem)\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m initial_eval\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SamplingError(\n\u001b[1;32m   1794\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial evaluation of model at starting point failed!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1795\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogp initial evaluation results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minitial_eval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can call `model.debug()` for more details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model/core.py:1825\u001b[0m, in \u001b[0;36mModel.point_logps\u001b[0;34m(self, point, round_vals)\u001b[0m\n\u001b[1;32m   1819\u001b[0m factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_RVs \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotentials\n\u001b[1;32m   1820\u001b[0m factor_logps_fn \u001b[38;5;241m=\u001b[39m [pt\u001b[38;5;241m.\u001b[39msum(factor) \u001b[38;5;28;01mfor\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogp(factors, \u001b[38;5;28msum\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1822\u001b[0m     factor\u001b[38;5;241m.\u001b[39mname: np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39masarray(factor_logp), round_vals)\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor, factor_logp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m   1824\u001b[0m         factors,\n\u001b[0;32m-> 1825\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_fn(factor_logps_fn)(point),\n\u001b[1;32m   1826\u001b[0m     )\n\u001b[1;32m   1827\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/pytensorf.py:624\u001b[0m, in \u001b[0;36mPointFunc.__call__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstate)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/compile/function/types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m t0_fn \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 970\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm()\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_subset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm(output_subset\u001b[38;5;241m=\u001b[39moutput_subset)\n\u001b[1;32m    973\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     restore_defaults()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/link/vm.py:411\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m                 old_s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m         raise_with_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfgraph, node, thunk)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_updates()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/link/utils.py:528\u001b[0m, in \u001b[0;36mraise_with_op\u001b[0;34m(fgraph, node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    523\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m error does not allow us to add an extra error message\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m# Some exception need extra parameter in inputs. So forget the\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m# extra long error message in that case.\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_trace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/link/vm.py:407\u001b[0m, in \u001b[0;36mLoop.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thunk, node, old_storage \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthunks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_thunk_clear, fillvalue\u001b[38;5;241m=\u001b[39m()\n\u001b[1;32m    406\u001b[0m     ):\n\u001b[0;32m--> 407\u001b[0m         thunk()\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m old_s \u001b[38;5;129;01min\u001b[39;00m old_storage:\n\u001b[1;32m    409\u001b[0m             old_s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/graph/op.py:524\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[0;32m--> 524\u001b[0m     r \u001b[38;5;241m=\u001b[39m p(n, [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m i], o)\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    526\u001b[0m         compute_map[o][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pytensor/tensor/blas.py:222\u001b[0m, in \u001b[0;36mGemv.perform\u001b[0;34m(self, node, inputs, out_storage)\u001b[0m\n\u001b[1;32m    219\u001b[0m gemv \u001b[38;5;241m=\u001b[39m _blas_gemv_fns[y\u001b[38;5;241m.\u001b[39mdtype]\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible shapes for gemv \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(beta * y + alpha * dot(A, x)). y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, A: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m check_init_y():\n\u001b[1;32m    228\u001b[0m     y\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for gemv (beta * y + alpha * dot(A, x)). y: (1,), A: (1, 1), x: (5000932,)\nApply node that caused the error: Gemv{inplace}(AllocEmpty{dtype='float64'}.0, 1.0, ExpandDims{axis=0}.0, [4.62 2.23 ... 6.98 6.75], 0.0)\nToposort index: 9\nInputs types: [TensorType(float64, shape=(1,)), TensorType(float64, shape=()), TensorType(float64, shape=(1, None)), TensorType(float64, shape=(5000932,)), TensorType(float64, shape=())]\nInputs shapes: [(1,), (), (1, 1), (5000932,), ()]\nInputs strides: [(8,), (), (8, 8), (8,), ()]\nInputs values: [array([0.]), array(1.), array([[-0.87218071]]), 'not shown', array(0.)]\nOutputs clients: [[Add(ExpandDims{axis=0}.0, Gemv{inplace}.0)]]\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node."
     ]
    }
   ],
   "source": [
    "with test_score_bayesian:\n",
    "    sample = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "721bc753-48d9-4faf-aa5c-5dd6d62366db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m az\u001b[38;5;241m.\u001b[39mplot_trace(sample, var_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_trace(sample, var_names=[\"beta0\", \"sigma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50dca0-691d-4c79-b448-8f4032580014",
   "metadata": {},
   "source": [
    "Got help below from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eca1e04-dbaf-42d5-9254-cf6bbf6f998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['ballCarrierSpeed']].values\n",
    "Y = df1['toPlayerDistanceToBallCarrier'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c85ba6c-0c62-4945-aa63-1ed5df640d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X.ndim == 1:\n",
    "    X = X[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99963137-87a6-4960-97ef-003b7f9f35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as test_score_bayesian:\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1])\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + pm.math.dot(X, beta)\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4775ea8d-b34c-412b-b70f-fa83953cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21e83753-5fef-4c34-8fd8-65b4a789919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33a0f8c9b345a88ab8fb8ea2f2c1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m test_score_bayesian:\n\u001b[0;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapt_diag\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "with test_score_bayesian:\n",
    "    sample = pm.sample(init=\"adapt_diag\", return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9293d9f4-ae81-4ca0-ac80-f900c4be9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df1.sample(1000)  # Smaller subset for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9295f838-3976-471b-93ef-f649581108cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3db620c58cf499db2731ef60fae558c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m Y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mY)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Sampling\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, tune\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjitter+adapt_diag\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df_sampled[['ballCarrierSpeed']].values  # replace with your feature names\n",
    "Y = df_sampled['toPlayerDistanceToBallCarrier'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define Bayesian model\n",
    "with pm.Model() as test_score_bayesian:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=5)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=5, shape=X_scaled.shape[1])\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + pm.math.dot(X_scaled, beta)\n",
    "\n",
    "    # Likelihood\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)\n",
    "\n",
    "    # Sampling\n",
    "    sample = pm.sample(draws=500, chains=2, tune=500, init=\"jitter+adapt_diag\", return_inferencedata=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
