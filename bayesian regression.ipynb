{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6051d31f-ace1-4257-89e6-a3ffa876e147",
   "metadata": {},
   "source": [
    "Source: https://medium.com/intuition/gentle-introduction-of-bayesian-linear-regression-c83da6b0d1f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9e0ea-6c99-46f2-8ec1-a6a3e12b12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytensor.tensor as at\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4165d7-6940-4da3-a596-5547ad19544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]\n",
      "scipy: 1.12.0\n",
      "numpy: 1.26.4\n",
      "matplotlib: 3.8.4\n",
      "pandas: 2.2.2\n",
      "sklearn: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the versions of libraries\n",
    "\n",
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Load libraries\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdbb0d1-57e2-41ea-9501-4c3402c6976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speed_dist_data_20231228.csv', header=0)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b876eda-d188-4abf-8d63-901011998676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the CSV file is: 5828669\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "row_count = len(df)\n",
    "\n",
    "print(f'The number of rows in the CSV file is: {row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35576e88-dbcc-4e9f-ba7e-0434d1a9a811",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/14940743/selecting-excluding-sets-of-columns-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab29640c-085b-4942-a18f-b4ee0a87753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['ballCarrierSpeed','toPlayerDistanceToBallCarrier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9bc896f-9e3d-4b43-86eb-77ef1589a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.duplicated()]\n",
    "df1 = df1.dropna().astype(float)\n",
    "\n",
    "columns = df1.columns.values[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ec408c-fd34-44d5-a449-929e13a1d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ballCarrierSpeed</th>\n",
       "      <th>toPlayerDistanceToBallCarrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.23</td>\n",
       "      <td>11.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.23</td>\n",
       "      <td>12.4279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.23</td>\n",
       "      <td>31.5794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ballCarrierSpeed  toPlayerDistanceToBallCarrier\n",
       "1              6.23                        11.0136\n",
       "2              6.23                        12.4279\n",
       "3              6.23                        31.5794"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2abf3c0-7f3e-4434-9a04-ae254d2a0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.duplicated()]\n",
    "df1 = df1.dropna().astype(float)\n",
    "\n",
    "columns = df1.columns.values[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f0813a-209a-4224-ae9f-98b4d9f21d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test size\n",
      "(5000932,) (555660,) (5000932,) (555660,)\n"
     ]
    }
   ],
   "source": [
    "X = df1.ballCarrierSpeed.values\n",
    "y = df1.toPlayerDistanceToBallCarrier.values\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "print('train and test size')\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ccbf055-314d-4bb7-89e4-5762b8d42f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.duplicated()]\n",
    "df1 = df1.dropna().astype(float)\n",
    "\n",
    "columns = df1.columns.values[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcbd9c4c-4e45-4553-b648-bd883d1497b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffc45843-98d0-41b8-91b2-7136cc4b04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_bayesian = pm.Model(coords={\"predictors\": columns})\n",
    "\n",
    "with test_score_bayesian:\n",
    "    # posterior variance\n",
    "    sigma = pm.HalfNormal(\"sigma\", 25)\n",
    "\n",
    "    # beta\n",
    "    beta = pm.Normal(\"beta\", 0, 10, dims=\"predictors\")\n",
    "    beta0 = pm.Normal(\"beta0\", 0, 10)\n",
    "\n",
    "    mu = beta0 + at.dot(X_train, beta)\n",
    "    \n",
    "    y_hat = pm.Normal(\"y_hat\", mu=mu, sigma=sigma, observed=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "030c25cb-3ce2-4924-96ae-de69285f8784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"398pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 398.50 259.91\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 255.91)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-255.91 394.5,-255.91 394.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>clusterpredictors (1)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.5,-129.95C280.5,-129.95 370.5,-129.95 370.5,-129.95 376.5,-129.95 382.5,-135.95 382.5,-141.95 382.5,-141.95 382.5,-231.91 382.5,-231.91 382.5,-237.91 376.5,-243.91 370.5,-243.91 370.5,-243.91 280.5,-243.91 280.5,-243.91 274.5,-243.91 268.5,-237.91 268.5,-231.91 268.5,-231.91 268.5,-141.95 268.5,-141.95 268.5,-135.95 274.5,-129.95 280.5,-129.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"325.5\" y=\"-137.75\" font-family=\"Times,serif\" font-size=\"14.00\">predictors (1)</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster5000932</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.5,-8C142.5,-8 232.5,-8 232.5,-8 238.5,-8 244.5,-14 244.5,-20 244.5,-20 244.5,-109.95 244.5,-109.95 244.5,-115.95 238.5,-121.95 232.5,-121.95 232.5,-121.95 142.5,-121.95 142.5,-121.95 136.5,-121.95 130.5,-115.95 130.5,-109.95 130.5,-109.95 130.5,-20 130.5,-20 130.5,-14 136.5,-8 142.5,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"204.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">5000932</text>\n",
       "</g>\n",
       "<!-- beta0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>beta0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"49.5\" cy=\"-198.43\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-209.73\" font-family=\"Times,serif\" font-size=\"14.00\">beta0</text>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-194.73\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"49.5\" y=\"-179.73\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- y_hat -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y_hat</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"187.5\" cy=\"-76.48\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-87.78\" font-family=\"Times,serif\" font-size=\"14.00\">y_hat</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-72.78\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-57.78\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- beta0&#45;&gt;y_hat -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>beta0&#45;&gt;y_hat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M73.79,-165.53C83.59,-153.68 95.43,-140.55 107.5,-129.95 117.44,-121.22 128.95,-112.84 140.08,-105.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142,-108.36 148.49,-99.98 138.19,-102.49 142,-108.36\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"187.5\" cy=\"-198.43\" rx=\"70.92\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-209.73\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-194.73\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-179.73\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;y_hat -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;y_hat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.5,-160.79C187.5,-149.38 187.5,-136.65 187.5,-124.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191,-124.31 187.5,-114.31 184,-124.31 191,-124.31\"/>\n",
       "</g>\n",
       "<!-- beta -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>beta</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"325.5\" cy=\"-198.43\" rx=\"49.49\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"325.5\" y=\"-209.73\" font-family=\"Times,serif\" font-size=\"14.00\">beta</text>\n",
       "<text text-anchor=\"middle\" x=\"325.5\" y=\"-194.73\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"325.5\" y=\"-179.73\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- beta&#45;&gt;y_hat -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>beta&#45;&gt;y_hat</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.2,-165.53C291.4,-153.68 279.57,-140.55 267.5,-129.95 257.55,-121.22 246.05,-112.84 234.92,-105.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236.8,-102.49 226.51,-99.98 232.99,-108.36 236.8,-102.49\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7c489e9d53d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "pm.model_to_graphviz(test_score_bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cfd0c06-2bcc-4c26-8459-f8c713ffa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_bayesian = pm.Model(coords={\"predictors\": columns})\n",
    "\n",
    "with test_score_bayesian:\n",
    "    # posterior variance\n",
    "    sigma = pm.HalfNormal(\"sigma\", 25)\n",
    "\n",
    "    # beta\n",
    "    beta = pm.Normal(\"beta\", 0, 10, dims=\"predictors\")\n",
    "    beta0 = pm.Normal(\"beta0\", 0, 10)\n",
    "\n",
    "    mu = beta0 + at.dot(X_train, beta)\n",
    "    \n",
    "    y_hat = pm.Normal(\"y_hat\", mu=mu, sigma=sigma, observed=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d427b774-54ff-46fb-98cf-39e30685f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, beta, beta0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2b064ad67845e79f7ab76d8d739990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:2004: RuntimeWarning: divide by zero encountered in divide\n",
      "  return x / y\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/tensor/elemwise.py:753: RuntimeWarning: divide by zero encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:1962: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return x - y\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/tensor/elemwise.py:753: RuntimeWarning: invalid value encountered in impl (vectorized)\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m test_score_bayesian:\n\u001b[0;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "with test_score_bayesian:\n",
    "    sample = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1c4caa8-54a8-4ab2-8e8a-d638bd902bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the CSV file is: 5828669\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows\n",
    "row_count = len(df)\n",
    "\n",
    "print(f'The number of rows in the CSV file is: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97089b77-6fb0-4a74-880b-1948fb9fa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform operations on df2\n",
    "df2 = df.sample(1000)[['ballCarrierSpeed','toPlayerDistanceToBallCarrier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f7afc7c-4e0d-458e-a92b-437bc9472535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[~df2.duplicated()]\n",
    "df2 = df2.dropna().astype(float)\n",
    "\n",
    "columns = df2.columns.values[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28b6690e-64b6-47be-abcb-da7c11424f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_bayesian = pm.Model(coords={\"predictors\": columns})\n",
    "\n",
    "with test_score_bayesian:\n",
    "    # posterior variance\n",
    "    sigma = pm.HalfNormal(\"sigma\", 25)\n",
    "\n",
    "    # beta\n",
    "    beta = pm.Normal(\"beta\", 0, 10, dims=\"predictors\")\n",
    "    bet5828669a0 = pm.Normal(\"beta0\", 0, 10)\n",
    "\n",
    "    mu = beta0 + at.dot(X_train, beta)\n",
    "    \n",
    "    y_hat = pm.Normal(\"y_hat\", mu=mu, sigma=sigma, observed=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a72590a-cee0-40a5-8f2b-a35c00e2f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bef99d7-923b-48f3-8a26-7c1cc92d705a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Random variables detected in the logp graph: {beta0}.\nThis can happen when DensityDist logp or Interval transform functions reference nonlocal variables,\nor when not all rvs have a corresponding value variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m test_score_bayesian:\n\u001b[0;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:714\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    713\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m step \u001b[38;5;241m=\u001b[39m assign_step_methods(model, step, methods\u001b[38;5;241m=\u001b[39mpm\u001b[38;5;241m.\u001b[39mSTEP_METHODS, step_kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, NUTS):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:215\u001b[0m, in \u001b[0;36massign_step_methods\u001b[0;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m methods_list: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[BlockedStep]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(methods \u001b[38;5;129;01mor\u001b[39;00m pm\u001b[38;5;241m.\u001b[39mSTEP_METHODS)\n\u001b[1;32m    214\u001b[0m selected_steps: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtype\u001b[39m[BlockedStep], \u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 215\u001b[0m model_logp \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlogp()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvalue_vars:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m assigned_vars:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;66;03m# determine if a gradient can be computed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/model/core.py:742\u001b[0m, in \u001b[0;36mModel.logp\u001b[0;34m(self, vars, jacobian, sum)\u001b[0m\n\u001b[1;32m    740\u001b[0m rv_logps: \u001b[38;5;28mlist\u001b[39m[TensorVariable] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rvs:\n\u001b[0;32m--> 742\u001b[0m     rv_logps \u001b[38;5;241m=\u001b[39m transformed_conditional_logp(\n\u001b[1;32m    743\u001b[0m         rvs\u001b[38;5;241m=\u001b[39mrvs,\n\u001b[1;32m    744\u001b[0m         rvs_to_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrvs_to_values,\n\u001b[1;32m    745\u001b[0m         rvs_to_transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrvs_to_transforms,\n\u001b[1;32m    746\u001b[0m         jacobian\u001b[38;5;241m=\u001b[39mjacobian,\n\u001b[1;32m    747\u001b[0m     )\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rv_logps, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# Replace random variables by their value variables in potential terms\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/logprob/basic.py:630\u001b[0m, in \u001b[0;36mtransformed_conditional_logp\u001b[0;34m(rvs, rvs_to_values, rvs_to_transforms, jacobian, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m rvs_in_logp_expressions \u001b[38;5;241m=\u001b[39m _find_unallowed_rvs_in_graph(logp_terms_list)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rvs_in_logp_expressions:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(RVS_IN_JOINT_LOGP_GRAPH_MSG \u001b[38;5;241m%\u001b[39m rvs_in_logp_expressions)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logp_terms_list\n",
      "\u001b[0;31mValueError\u001b[0m: Random variables detected in the logp graph: {beta0}.\nThis can happen when DensityDist logp or Interval transform functions reference nonlocal variables,\nor when not all rvs have a corresponding value variable."
     ]
    }
   ],
   "source": [
    "with test_score_bayesian:\n",
    "    sample = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f66a0-764c-4871-bd6f-8f1dfbd117f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "721bc753-48d9-4faf-aa5c-5dd6d62366db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m az\u001b[38;5;241m.\u001b[39mplot_trace(sample, var_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_trace(sample, var_names=[\"beta0\", \"sigma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50dca0-691d-4c79-b448-8f4032580014",
   "metadata": {},
   "source": [
    "Got help below from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7eca1e04-dbaf-42d5-9254-cf6bbf6f998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['ballCarrierSpeed']].values\n",
    "Y = df1['toPlayerDistanceToBallCarrier'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c85ba6c-0c62-4945-aa63-1ed5df640d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X.ndim == 1:\n",
    "    X = X[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99963137-87a6-4960-97ef-003b7f9f35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as test_score_bayesian:\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=10)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1])\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + pm.math.dot(X, beta)\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4775ea8d-b34c-412b-b70f-fa83953cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "21e83753-5fef-4c34-8fd8-65b4a789919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33a0f8c9b345a88ab8fb8ea2f2c1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/pytensor/scalar/basic.py:3098: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m test_score_bayesian:\n\u001b[0;32m----> 2\u001b[0m     sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapt_diag\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "with test_score_bayesian:\n",
    "    sample = pm.sample(init=\"adapt_diag\", return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9293d9f4-ae81-4ca0-ac80-f900c4be9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df1.sample(1000)  # Smaller subset for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9295f838-3976-471b-93ef-f649581108cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3db620c58cf499db2731ef60fae558c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m Y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mY)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Sampling\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, tune\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjitter+adapt_diag\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df_sampled[['ballCarrierSpeed']].values  # replace with your feature names\n",
    "Y = df_sampled['toPlayerDistanceToBallCarrier'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define Bayesian model\n",
    "with pm.Model() as test_score_bayesian:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=5)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=5, shape=X_scaled.shape[1])\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + pm.math.dot(X_scaled, beta)\n",
    "\n",
    "    # Likelihood\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)\n",
    "\n",
    "    # Sampling\n",
    "    sample = pm.sample(draws=500, chains=2, tune=500, init=\"jitter+adapt_diag\", return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693cbe5-782c-4c5f-ba2e-97afee3d3e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a904764-1952-4f8e-baac-7cb4e8b71408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled_500 = df1.sample(500)  # Smaller subset for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3676f6c-5be7-40f0-b947-e68a0d6aead7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [alpha, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18311cdffe3a4ca99b4a227266aadd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m Y_obs \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_obs\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu, sigma\u001b[38;5;241m=\u001b[39msigma, observed\u001b[38;5;241m=\u001b[39mY)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Sampling\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m sample \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39msample(draws\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, tune\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjitter+adapt_diag\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_inferencedata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:871\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sample_return(\n\u001b[1;32m    872\u001b[0m     run\u001b[38;5;241m=\u001b[39mrun,\n\u001b[1;32m    873\u001b[0m     traces\u001b[38;5;241m=\u001b[39mtraces,\n\u001b[1;32m    874\u001b[0m     tune\u001b[38;5;241m=\u001b[39mtune,\n\u001b[1;32m    875\u001b[0m     t_sampling\u001b[38;5;241m=\u001b[39mt_sampling,\n\u001b[1;32m    876\u001b[0m     discard_tuned_samples\u001b[38;5;241m=\u001b[39mdiscard_tuned_samples,\n\u001b[1;32m    877\u001b[0m     compute_convergence_checks\u001b[38;5;241m=\u001b[39mcompute_convergence_checks,\n\u001b[1;32m    878\u001b[0m     return_inferencedata\u001b[38;5;241m=\u001b[39mreturn_inferencedata,\n\u001b[1;32m    879\u001b[0m     keep_warning_stat\u001b[38;5;241m=\u001b[39mkeep_warning_stat,\n\u001b[1;32m    880\u001b[0m     idata_kwargs\u001b[38;5;241m=\u001b[39midata_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    881\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    882\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/sampling/mcmc.py:902\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Pick and slice chains to keep the maximum number of samples\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discard_tuned_samples:\n\u001b[0;32m--> 902\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, tune)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     traces, length \u001b[38;5;241m=\u001b[39m _choose_chains(traces, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pymc/backends/base.py:593\u001b[0m, in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m    591\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trace) \u001b[38;5;241m-\u001b[39m tune) \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m traces]\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough samples to build a trace.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lengths)\n\u001b[1;32m    596\u001b[0m l_sort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)[idxs]\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df_sampled_500[['ballCarrierSpeed']].values  # replace with your feature names\n",
    "Y = df_sampled_500['toPlayerDistanceToBallCarrier'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define Bayesian model\n",
    "with pm.Model() as test_score_bayesian:\n",
    "    # Priors\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=5)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=5, shape=X_scaled.shape[1])\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mu = alpha + pm.math.dot(X_scaled, beta)\n",
    "\n",
    "    # Likelihood\n",
    "    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=Y)\n",
    "\n",
    "    # Sampling\n",
    "    sample = pm.sample(draws=500, chains=2, tune=500, init=\"jitter+adapt_diag\", return_inferencedata=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
